{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53c5efcd-f459-4d57-9550-bbbe89bcee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81688c2-d61b-4a54-a4cc-6dd0b1587b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                               # csv reader\n",
    "import nltk\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7f726f-392a-44d6-a423-2d6424b3e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def load_data(path, raw_data):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t') ## whole of dataset\n",
    "        for line in reader:  ## every line[i] is one feature (or label)\n",
    "            if line[0] == \"Id\":  # skip header row \n",
    "                continue\n",
    "            ## We read all the features here\n",
    "            (sentence, subject, speaker, speaker_job_title, state_info, party_affiliation, total_barely_true_counts, \n",
    "           total_false_counts, total_half_true_counts, total_mostly_true_counts, total_pants_on_fire_counts, context ,label) = parse_data_line(line)\n",
    "            raw_data.append((sentence, subject, speaker, speaker_job_title, state_info, party_affiliation, total_barely_true_counts, \n",
    "           total_false_counts, total_half_true_counts, total_mostly_true_counts, total_pants_on_fire_counts, context ,label))\n",
    "    f.close()\n",
    "\n",
    "def split_and_preprocess_data(raw_data, train_data, test_data, train_num_data, test_num_data, percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    global_feature_dict = Counter()\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    tr_idx = 0\n",
    "    for (sentence, subject, speaker, speaker_job_title, state_info, party_affiliation, total_barely_true_counts, \n",
    "           total_false_counts, total_half_true_counts, total_mostly_true_counts, total_pants_on_fire_counts, context ,label) in raw_data[:num_training_samples]:\n",
    "        ## split subject by ',' delimeter\n",
    "        subject = re.split(',', subject)\n",
    "        \n",
    "        ## convert state_info to lowercase\n",
    "        state_info = state_info.lower()\n",
    "        \n",
    "        ## consider the combination of sentence, sibject, and context as one single document (sentece) and pre-process it\n",
    "        sentence = pre_process(sentence + \" \" + ' '.join(subject) + \" \" + context, stop_words)\n",
    "        \n",
    "        ## This is counter for other features --> speaker, speaker_job_title, state_info, party_affiliation\n",
    "        other_feature = Counter()\n",
    "        \n",
    "        ## by this lopp, we avoid of inserting 'none':1 or '':1 to our featureset dictionary\n",
    "        for feat in [speaker, speaker_job_title, state_info, party_affiliation]:\n",
    "            if feat == 'none' or feat == '':\n",
    "                continue\n",
    "            else:\n",
    "                other_feature.update({feat:1})\n",
    "            \n",
    "        ## Add textual features to our training textual dataset (train_data)\n",
    "        train_data.append((to_feature_vector(sentence) + other_feature,label))\n",
    "        \n",
    "        ## Add numerical features to our training numerical dataset (train_num_data)\n",
    "        train_num_data.append([total_barely_true_counts, total_false_counts, total_half_true_counts,\n",
    "                               total_mostly_true_counts, total_pants_on_fire_counts, label])\n",
    "        \n",
    "\n",
    "    for (sentence, subject, speaker, speaker_job_title, state_info, party_affiliation, total_barely_true_counts, \n",
    "           total_false_counts, total_half_true_counts, total_mostly_true_counts, total_pants_on_fire_counts, context ,label) in raw_data[num_training_samples:]:\n",
    "        ## split subject by ',' delimeter\n",
    "        subject = re.split(',', subject)\n",
    "        \n",
    "        ## convert state_info to lowercase\n",
    "        state_info = state_info.lower()\n",
    "        \n",
    "        ## consider the combination of sentence, sibject, and context as one single document (sentece) and pre-process it\n",
    "        sentence = pre_process(sentence + \" \" + ' '.join(subject) + \" \" + context, stop_words)\n",
    "        \n",
    "        ## This is counter for other features --> speaker, speaker_job_title, state_info, party_affiliation\n",
    "        other_feature = Counter()\n",
    "        \n",
    "        ## by this lopp, we avoid of inserting 'none':1 or '':1 to our featureset dictionary\n",
    "        for feat in [speaker, speaker_job_title, state_info, party_affiliation]:\n",
    "            if feat == 'none' or feat == '':\n",
    "                continue\n",
    "            else:\n",
    "                other_feature.update({feat:1})\n",
    "                \n",
    "        ## Add textual features to our testing textual dataset (test_data)\n",
    "        test_data.append((to_feature_vector(sentence) + other_feature ,label))\n",
    "        \n",
    "        ## Add numerical features to our testing numerical dataset (test_num_data)\n",
    "        test_num_data.append([total_barely_true_counts, total_false_counts, total_half_true_counts,\n",
    "                               total_mostly_true_counts, total_pants_on_fire_counts, label])\n",
    "        # tst_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea00b9c9-1a4a-4bab-a420-1b6eec1f3022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    \"\"\"Converts the multiple classes into two,\n",
    "    making it a binary distinction between fake news and real.\"\"\"\n",
    "    #return label\n",
    "    # Converting the multiclass labels to binary label\n",
    "    labels_map = {\n",
    "        'true': 'REAL',\n",
    "        'mostly-true': 'REAL',\n",
    "        'half-true': 'REAL',\n",
    "        'false': 'FAKE',\n",
    "        'barely-true': 'FAKE',\n",
    "        'pants-fire': 'FAKE'\n",
    "    }\n",
    "    return labels_map[label]\n",
    "\n",
    "def parse_data_line(data_line): ## input: 1 line of dataset\n",
    "    # Should return a tuple of the label as just FAKE or REAL and the statement\n",
    "    # e.g. (label, statement) \n",
    "    \n",
    "    ## I make the features separated here, then pass them as a big tuple\n",
    "    label = convert_label(data_line[1])\n",
    "    sentence = data_line[2]\n",
    "    # _id = data_line[0]\n",
    "    subject = data_line[3]\n",
    "    speaker = data_line[4]\n",
    "    speaker_job_title = data_line[5]\n",
    "    state_info = data_line[6]\n",
    "    party_affiliation = data_line[7]\n",
    "    total_barely_true_counts = data_line[8]\n",
    "    total_false_counts = data_line[9]\n",
    "    total_half_true_counts = data_line[10]\n",
    "    total_mostly_true_counts = data_line[11]\n",
    "    total_pants_on_fire_counts = data_line[12]\n",
    "    context = data_line[13]\n",
    "    \n",
    "    return (sentence, subject, speaker, speaker_job_title, state_info, party_affiliation, total_barely_true_counts, \n",
    "           total_false_counts, total_half_true_counts, total_mostly_true_counts, total_pants_on_fire_counts, context ,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adb6ccd6-8291-4213-81df-77a78525dd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "## set of stop words from nltk corpus\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Input: a string of one statement \n",
    "# Output: list of tokens in that sentence\n",
    "\n",
    "## return --> list of tokens\n",
    "def pre_process(text, stop_words):\n",
    "    ## Lowercase\n",
    "    lower_text = text.lower()\n",
    "    ## replace '-' by ' '\n",
    "    lower_text = lower_text.replace('-', ' ')\n",
    "    ## Punctuation\n",
    "    no_p_text = \"\".join([char for char in lower_text if char not in string.punctuation])\n",
    "    ## Tokenizing\n",
    "    words = word_tokenize(no_p_text)\n",
    "    no_stop_word = [word for word in words if word not in stop_words]\n",
    "    ## Lemmization\n",
    "    wordnet_lem = WordNetLemmatizer()\n",
    "    ## Stemming\n",
    "    # ps = PorterStemmer() \n",
    "    \n",
    "    return [wordnet_lem.lemmatize(token) for token in no_stop_word]\n",
    "    # return [ps.stem(token) for token in no_stop_word]\n",
    "    # return no_stop_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a50c59-4db0-48d3-9f49-a384a531abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "## input: one statement's token\n",
    "## global_fd should be a counter\n",
    "## global_sd should be a dict of set\n",
    "## Global feature dictionary\n",
    "## Global sentence dictionary --> {feature : {sent1, sent2, sent5, ...}}\n",
    "def to_feature_vector(tokens):\n",
    "    # Should return a dictionary containing features as keys, and weights as values\n",
    "    ## Update global feature dictionary\n",
    "    \n",
    "    ## We insert unigram tokens by initializing token as a counter\n",
    "    word_dict = Counter(tokens)\n",
    "    \n",
    "    ## Here we add bigram and trigram tokens to our dictionary\n",
    "        \n",
    "    # Add bigram\n",
    "    bigram_keys = []\n",
    "    for i in range(len(tokens)-1):\n",
    "        new_key = tokens[i] + ' ' + tokens[i+1]\n",
    "        bigram_keys.append(new_key)\n",
    "    \n",
    "    ## Update the counter\n",
    "    word_dict.update(bigram_keys)\n",
    "\n",
    "        \n",
    "    ## Add trigram\n",
    "    trigram_keys = []\n",
    "    for i in range(len(tokens)-2):\n",
    "        new_key = tokens[i] + ' ' + tokens[i+1] + ' ' + tokens[i+2]\n",
    "        trigram_keys.append(new_key)\n",
    "\n",
    "    ## Update the counter\n",
    "    word_dict.update(trigram_keys)\n",
    "        \n",
    "    # DESCRIBE YOUR METHOD IN WORDS\n",
    "    return word_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc57f488-7033-4c99-844d-967cb1ece941",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function will be applied to train set in cross validation, to compute both global dicts, for tf, idf\n",
    "## This below function update global statement dictionary, which shows the index of sentences that contains each word\n",
    "## {word1: {Sentence_i, Sentence_j, ....}, word2: {Sentece_k, ....}}\n",
    "## It is basically a dict of set\n",
    "def build_global_dicts(train_data, global_fd, global_sd):\n",
    "    tr_idx = 0\n",
    "    for tokens, label in train_data:\n",
    "        global_fd.update(tokens)\n",
    "        for token in tokens:\n",
    "            global_sd[token].add(tr_idx)\n",
    "        tr_idx += 1\n",
    "        \n",
    "        \n",
    "from math import log10\n",
    "from collections import defaultdict\n",
    "\n",
    "## This function does the tf_idf (assign thw weights) for both train and test in cross validation\n",
    "## Pay attention that the 'global_sentence_dict' is only filled by train data above, and there will be no data leakage.\n",
    "def assign_weights(train_data, global_sentence_dict):\n",
    "    for tokens, label in train_data:\n",
    "        ## tokens is Counter\n",
    "        f_td = tokens\n",
    "        denom = [0,0,0]\n",
    "        for token in tokens.keys():\n",
    "            # For tf-idf in n-grams case\n",
    "            ## Unigram\n",
    "            if len(token.split()) == 1:\n",
    "                denom[0] += 1\n",
    "            ## Bigram\n",
    "            elif len(token.split()) == 2:\n",
    "                denom[1] += 1\n",
    "            ## Trigram\n",
    "            elif len(token.split()) == 3:\n",
    "                denom[2] += 1\n",
    "        for token, weight in tokens.items():\n",
    "            ## Unigram\n",
    "            if len(token.split()) == 1:\n",
    "                tf = f_td[token] / denom[0]\n",
    "            ## Bigram\n",
    "            elif len(token.split()) == 2:\n",
    "                tf = f_td[token] / denom[1]\n",
    "            ## Trigram\n",
    "            elif len(token.split()) == 3:\n",
    "                tf = f_td[token] / denom[2]\n",
    "        \n",
    "            # tf = 2 * f_td[token] / sum(f_td.values())\n",
    "                \n",
    "            ## idf term\n",
    "            idf = log10(len(train_data) / ( 1+len(global_sentence_dict[token]) ) ) + 1\n",
    "            \n",
    "            ## Final weight\n",
    "            tokens[token] = tf * idf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7d7c7b2-f005-4939-b026-322e58823f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "\n",
    "def train_classifier(data):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('svc', LinearSVC(C=2))])\n",
    "    return SklearnClassifier(pipeline).train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ce4dee-b9da-4eef-b875-6886d4afee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import copy\n",
    "\n",
    "def cross_validate(dataset, num_dataset, folds):\n",
    "    fold_size = int(len(dataset)/folds)\n",
    "    last_iteration = False\n",
    "    accuracy, recall, precision, f1 = [], [], [], []\n",
    "    text_accuracy, text_recall, text_precision, text_f1 = [], [], [], []\n",
    "    for test_start_idx in range(0, len(dataset), int(fold_size)):\n",
    "        if test_start_idx == (folds-1)*fold_size:\n",
    "            ## This is the last iteration\n",
    "            print(\"test fold form {} to {}:\".format(test_start_idx, len(dataset)))\n",
    "            test_set = dataset[test_start_idx:]\n",
    "            num_test_set = num_dataset[test_start_idx:]\n",
    "            \n",
    "            train_set = dataset[:test_start_idx]\n",
    "            ## Textual dataset for trainin --> first half of train data for training of textual classifier\n",
    "            train_set_text = train_set[0:3686]\n",
    "            \n",
    "            ## Textual dataset for testing --> second half of train data for testing of textual classifier\n",
    "            test_set_text = train_set[3686:]\n",
    "            \n",
    "            num_train_set = num_dataset[:test_start_idx]\n",
    "            \n",
    "            ## Numerical dataset for training\n",
    "            num_train_set = num_train_set[3686:]\n",
    "            \n",
    "            ## TF-IDF\n",
    "            global_feature_dict = Counter()\n",
    "            global_sentence_dict = defaultdict(set)\n",
    "            build_global_dicts(train_set_text, global_feature_dict, global_sentence_dict)\n",
    "            tmp_train = copy.deepcopy(train_set_text)\n",
    "            tmp_test = copy.deepcopy(test_set_text)\n",
    "            ## Assign TF-IDF weights here\n",
    "            assign_weights(tmp_train, global_sentence_dict)\n",
    "            assign_weights(tmp_test, global_sentence_dict)\n",
    "             \n",
    "            ## Train text classifier\n",
    "            LinearSVC_classifier = train_classifier(tmp_train)\n",
    "            ## Text feature is prediction which will be concated to numerical dataset\n",
    "            text_featureset, a = separate_test_set(tmp_test)\n",
    "            train_text_predicition = np.array(predict_labels(text_featureset, LinearSVC_classifier))\n",
    "            \n",
    "            ## Convert the predicition of text classifier (Real, Fake) to (1, 0) \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            train_text_predicition = le.fit_transform(train_text_predicition)\n",
    "            \n",
    "            ## Now we prepare data for our final model --> Numeric data from dataset + Prediction of text classifier on each sample in numerical train set\n",
    "            ## Standardization of numeric data\n",
    "            \n",
    "            _num_train_set = copy.deepcopy(np.array(num_train_set))\n",
    "            x_train_num = _num_train_set[:, :5]\n",
    "            y_train_num = _num_train_set[:, -1]\n",
    "            ## Add text feature to num_data\n",
    "            x_train_num = np.concatenate((x_train_num, train_text_predicition.reshape(x_train_num.shape[0],1)),  axis=1)\n",
    "            ## Now we normalize our new data consisting of 6 columns\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            x_train_num_standard = scaler.fit_transform(x_train_num)\n",
    "            ## Now we train data on our final numeric classifier\n",
    "            clf = svm.SVC(C=100, gamma=1)\n",
    "            clf.fit(x_train_num_standard, y_train_num)\n",
    "            \n",
    "            \n",
    "            ## So far we train our final classifier, now we test our text_classifier on test data\n",
    "            test_featureset, test_labels = separate_test_set(test_set)\n",
    "            test_text_prediction = predict_labels(test_featureset, LinearSVC_classifier)\n",
    "            \n",
    "            ## Now we print the result of text classifier on test data\n",
    "            text_accuracy.append(accuracy_score(test_labels, test_text_prediction))\n",
    "            text_recall.append(recall_score(test_labels, test_text_prediction, average='weighted'))\n",
    "            text_precision.append(precision_score(test_labels, test_text_prediction, average='weighted'))\n",
    "            text_f1.append(f1_score(test_labels, test_text_prediction, average='weighted'))\n",
    "            print('This is the classification report with using text features only:')\n",
    "            print('\\n')\n",
    "            print(classification_report(test_labels, test_text_prediction))\n",
    "            \n",
    "            ## Now we consider the text classifier prediction as a new feature for our numeric dataset\n",
    "            ## Convert the predicition of text classifier (Real, Fake) to (1, 0) \n",
    "            _le = preprocessing.LabelEncoder()\n",
    "            test_text_prediction = _le.fit_transform(test_text_prediction)\n",
    "            \n",
    "            \n",
    "            ## Now we build our test dataset\n",
    "            _num_test_set = copy.deepcopy(np.array(num_test_set))\n",
    "            ## These are numerical features\n",
    "            x_test_num = _num_test_set[:, :5]\n",
    "            y_test_num = _num_test_set[:, -1]\n",
    "            ## Add text feature to numerical features\n",
    "            x_test_num = np.concatenate((x_test_num, test_text_prediction.reshape(x_test_num.shape[0],1)),  axis=1)\n",
    "            ## Now we normalize our test_dataset with the standardizer that we already have\n",
    "            x_test_num_standard = scaler.transform(x_test_num)\n",
    "            \n",
    "            ## Now we have test data, it's time for testing our final classifier --> clf\n",
    "            final_prediction = clf.predict(x_test_num_standard)\n",
    "            \n",
    "            ## This is the final metric for our combination of both textual and numerical classifiers\n",
    "            accuracy.append(accuracy_score(test_labels, final_prediction))\n",
    "            recall.append(recall_score(test_labels, final_prediction, average='weighted'))\n",
    "            precision.append(precision_score(test_labels, final_prediction, average='weighted'))\n",
    "            f1.append(f1_score(test_labels, final_prediction, average='weighted'))\n",
    "            print('This is the classification report using the combination of numerical and text features:')\n",
    "            print('\\n')\n",
    "            print(classification_report(test_labels, final_prediction))\n",
    "            print('---------------------------------------------------------')\n",
    "            print('---------------------------------------------------------')\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            if test_start_idx == 0:\n",
    "                test_set = dataset[test_start_idx:(test_start_idx+fold_size)]\n",
    "                num_test_set = num_dataset[test_start_idx:(test_start_idx+fold_size)]\n",
    "                \n",
    "                train_set = dataset[test_start_idx+fold_size:]\n",
    "                ## Textual dataset for trainin --> first half of train data for training of textual classifier\n",
    "                train_set_text = train_set[0:3686]\n",
    "                \n",
    "                ## Textual dataset for testing --> second half of train data for testing of textual classifier\n",
    "                test_set_text = train_set[3686:]\n",
    "                \n",
    "                # print('This is train_set size: {}'.format(len(train_set)))\n",
    "                num_train_set = num_dataset[test_start_idx+fold_size:]\n",
    "                num_train_set = num_train_set[3686:]\n",
    "                print(\"test fold form {} to {}:\".format(test_start_idx, test_start_idx+fold_size-1))\n",
    "            else:\n",
    "                test_set = dataset[test_start_idx:(test_start_idx+fold_size)]\n",
    "                num_test_set = num_dataset[test_start_idx:(test_start_idx+fold_size)]\n",
    "                \n",
    "                train_set = dataset[0:test_start_idx] + dataset[(test_start_idx+fold_size):]\n",
    "                ## Textual dataset for trainin --> first half of train data for training of textual classifier\n",
    "                train_set_text = train_set[0:3686]\n",
    "                ## Textual dataset for testing --> second half of train data for testing of textual classifier\n",
    "                test_set_text = train_set[3686:]\n",
    "                \n",
    "                # print('This is train_set size: {}'.format(len(train_set)))\n",
    "                num_train_set = num_dataset[0:test_start_idx] + num_dataset[(test_start_idx+fold_size):]\n",
    "                \n",
    "                ## Numerical dataset for training\n",
    "                num_train_set = num_train_set[3686:]\n",
    "                print(\"test fold form {} to {}:\".format(test_start_idx, test_start_idx+fold_size-1))\n",
    "            \n",
    "            ## TF-IDF\n",
    "            global_feature_dict = Counter()\n",
    "            global_sentence_dict = defaultdict(set)\n",
    "            build_global_dicts(train_set_text, global_feature_dict, global_sentence_dict)\n",
    "            tmp_train = copy.deepcopy(train_set_text)\n",
    "            tmp_test = copy.deepcopy(test_set_text)\n",
    "            ## Assign TF-IDF weights here\n",
    "            assign_weights(tmp_train, global_sentence_dict)\n",
    "            assign_weights(tmp_test, global_sentence_dict)\n",
    "             \n",
    "            ## Train text classifier\n",
    "            LinearSVC_classifier = train_classifier(tmp_train)\n",
    "            ## Text feature is prediction which will be concated to numerical dataset\n",
    "            text_featureset, a = separate_test_set(tmp_test)\n",
    "            train_text_predicition = np.array(predict_labels(text_featureset, LinearSVC_classifier))\n",
    "            \n",
    "            ## Convert the predicition of text classifier (Real, Fake) to (1, 0) \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            train_text_predicition = le.fit_transform(train_text_predicition)\n",
    "            \n",
    "            ## Now we prepare data for our final model --> Numeric data from dataset + Prediction of text classifier on each sample in numerical train set\n",
    "            ## Standardization of numeric data\n",
    "            \n",
    "            _num_train_set = copy.deepcopy(np.array(num_train_set))\n",
    "            x_train_num = _num_train_set[:, :5]\n",
    "            y_train_num = _num_train_set[:, -1]\n",
    "            ## Add text feature to num_data\n",
    "            x_train_num = np.concatenate((x_train_num, train_text_predicition.reshape(x_train_num.shape[0],1)),  axis=1)\n",
    "            ## Now we normalize our new data consisting of 6 columns\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            x_train_num_standard = scaler.fit_transform(x_train_num)\n",
    "            ## Now we train data on our final numeric classifier\n",
    "            clf = svm.SVC(C=100, gamma=1)\n",
    "            clf.fit(x_train_num_standard, y_train_num)\n",
    "            \n",
    "            \n",
    "            ## So far we train our final classifier, now we test our text_classifier on test data\n",
    "            test_featureset, test_labels = separate_test_set(test_set)\n",
    "            test_text_prediction = predict_labels(test_featureset, LinearSVC_classifier)\n",
    "            \n",
    "            ## Now we print the result of text classifier on test data\n",
    "            text_accuracy.append(accuracy_score(test_labels, test_text_prediction))\n",
    "            text_recall.append(recall_score(test_labels, test_text_prediction, average='weighted'))\n",
    "            text_precision.append(precision_score(test_labels, test_text_prediction, average='weighted'))\n",
    "            text_f1.append(f1_score(test_labels, test_text_prediction, average='weighted'))\n",
    "            print('This is the classification report with using text features only:')\n",
    "            print('\\n')\n",
    "            print(classification_report(test_labels, test_text_prediction))\n",
    "            \n",
    "            ## Now we consider the text classifier prediction as a new feature for our numeric dataset\n",
    "            ## Convert the predicition of text classifier (Real, Fake) to (1, 0) \n",
    "            _le = preprocessing.LabelEncoder()\n",
    "            test_text_prediction = _le.fit_transform(test_text_prediction)\n",
    "            \n",
    "            \n",
    "            ## Now we build our test dataset\n",
    "            _num_test_set = copy.deepcopy(np.array(num_test_set))\n",
    "            ## These are numerical features\n",
    "            x_test_num = _num_test_set[:, :5]\n",
    "            y_test_num = _num_test_set[:, -1]\n",
    "            ## Add text feature to numerical features\n",
    "            x_test_num = np.concatenate((x_test_num, test_text_prediction.reshape(x_test_num.shape[0],1)),  axis=1)\n",
    "            ## Now we normalize our test_dataset with the standardizer that we already have\n",
    "            x_test_num_standard = scaler.transform(x_test_num)\n",
    "            \n",
    "            ## Now we have test data, it's time for testing our final classifier --> clf\n",
    "            final_prediction = clf.predict(x_test_num_standard)\n",
    "            \n",
    "            ## This is the final metric for our combination of both textual and numerical classifiers\n",
    "            accuracy.append(accuracy_score(test_labels, final_prediction))\n",
    "            recall.append(recall_score(test_labels, final_prediction, average='weighted'))\n",
    "            precision.append(precision_score(test_labels, final_prediction, average='weighted'))\n",
    "            f1.append(f1_score(test_labels, final_prediction, average='weighted'))\n",
    "            print('This is the classification report using the combination of numerical and text features:')\n",
    "            print('\\n')\n",
    "            print(classification_report(test_labels, final_prediction))\n",
    "            print('---------------------------------------------------------')\n",
    "            print('---------------------------------------------------------')\n",
    "        \n",
    "        # FILL IN THE METHOD HERE\n",
    "    return [np.mean(accuracy), np.mean(recall), np.mean(precision), np.mean(f1)], [np.mean(text_accuracy), np.mean(text_recall), np.mean(text_precision), np.mean(text_f1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77228fec-a3fb-40a7-9463-8cc3e56b5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predict_labels(samples, classifier):\n",
    "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
    "    return classifier.classify_many(samples)\n",
    "\n",
    "def predict_label_from_raw(sample, classifier):\n",
    "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
    "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))\n",
    "\n",
    "## This function just seperate a dataset into features and labels.\n",
    "def separate_test_set(test_set):\n",
    "    feature_set = []\n",
    "    labels = []\n",
    "    for pair in test_set:\n",
    "        feature_set.append(pair[0])\n",
    "        labels.append(pair[1])\n",
    "    return feature_set, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b908eeb-88f6-4597-a303-3465923c3286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 10241 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
      "Training Samples: \n",
      "8192\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# loading reviews\n",
    "# initialize global lists that will be appended to by the methods below\n",
    "raw_data = []          # the filtered data from the dataset file\n",
    "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "# references to the data files\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "# Do the actual stuff (i.e. call the functions we've made)\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "load_data(data_file_path, raw_data) \n",
    "\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "# You do the cross validation on the 80% (training data)\n",
    "# We print the number of training samples and the number of features before the split\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "train_num_data = []\n",
    "test_num_data = []\n",
    "split_and_preprocess_data(raw_data=raw_data, train_data=train_data, test_data=test_data, train_num_data=train_num_data, \n",
    "                          test_num_data=test_num_data, percentage=0.8)\n",
    "\n",
    "# We print the number of training samples and the number of features after the split\n",
    "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Training Samples: \", len(train_data), sep='\\n')\n",
    "\n",
    "# print(train_data)\n",
    "# print('---------------------------------')\n",
    "# print(test_data)\n",
    "# print(train_data[1023:1028])\n",
    "\n",
    "# cross_validate(dataset=train_data, folds=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "202d16d6-bc45-4867-81da-09895619d0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "print(len(train_num_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53b5b9e5-e6c2-4b6e-9a8c-653e707b5023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Counter({'welfare': 2, 'congress': 1, 'approves': 1, 'bill': 1, 'offering': 1, 'free': 1, 'car': 1, 'recipient': 1, 'web': 1, 'post': 1, 'congress approves': 1, 'approves bill': 1, 'bill offering': 1, 'offering free': 1, 'free car': 1, 'car welfare': 1, 'welfare recipient': 1, 'recipient welfare': 1, 'welfare web': 1, 'web post': 1, 'congress approves bill': 1, 'approves bill offering': 1, 'bill offering free': 1, 'offering free car': 1, 'free car welfare': 1, 'car welfare recipient': 1, 'welfare recipient welfare': 1, 'recipient welfare web': 1, 'welfare web post': 1, 'americannewscom': 1}), 'FAKE')\n"
     ]
    }
   ],
   "source": [
    "## A sample of dataset before applying tf-idf (I applied it in cross validation loop for each iteration separately.)\n",
    "print(train_data[1980])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12af4713-37e2-4daf-b510-c968c118659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Congress Approves Bill Offering Free Cars To Welfare Recipients.', 'welfare', 'americannewscom', '', '', 'none', '0', '0', '0', '0', '2', 'a web post', 'FAKE')\n"
     ]
    }
   ],
   "source": [
    "## Corresponding raw data to compare with above, to see the effect of pre-processing\n",
    "print(raw_data[1980])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251603f-9b65-468e-8366-24b52d3c145f",
   "metadata": {},
   "source": [
    "# Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf0f7101-48da-44e5-8d64-74d83ef2a8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV 1/5] END .........C=1, gamma=10, kernel=rbf;, score=0.727 total time=   0.3s\n",
      "[CV 2/5] END .........C=1, gamma=10, kernel=rbf;, score=0.713 total time=   0.3s\n",
      "[CV 3/5] END .........C=1, gamma=10, kernel=rbf;, score=0.706 total time=   0.3s\n",
      "[CV 4/5] END .........C=1, gamma=10, kernel=rbf;, score=0.745 total time=   0.3s\n",
      "[CV 5/5] END .........C=1, gamma=10, kernel=rbf;, score=0.734 total time=   0.3s\n",
      "[CV 1/5] END .....C=1, gamma=10, kernel=sigmoid;, score=0.496 total time=   0.4s\n",
      "[CV 2/5] END .....C=1, gamma=10, kernel=sigmoid;, score=0.526 total time=   0.4s\n",
      "[CV 3/5] END .....C=1, gamma=10, kernel=sigmoid;, score=0.487 total time=   0.4s\n",
      "[CV 4/5] END .....C=1, gamma=10, kernel=sigmoid;, score=0.502 total time=   0.4s\n",
      "[CV 5/5] END .....C=1, gamma=10, kernel=sigmoid;, score=0.505 total time=   0.4s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.638 total time=   0.3s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.606 total time=   0.4s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.668 total time=   0.3s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.679 total time=   0.3s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.695 total time=   0.3s\n",
      "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.571 total time=   0.4s\n",
      "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.537 total time=   0.5s\n",
      "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.580 total time=   0.4s\n",
      "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.560 total time=   0.4s\n",
      "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.514 total time=   0.5s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.607 total time=   0.3s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.593 total time=   0.3s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.618 total time=   0.3s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.641 total time=   0.3s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.657 total time=   0.4s\n",
      "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.585 total time=   0.4s\n",
      "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.607 total time=   0.4s\n",
      "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.601 total time=   0.4s\n",
      "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.568 total time=   0.4s\n",
      "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.593 total time=   0.4s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.605 total time=   0.4s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.584 total time=   0.4s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.619 total time=   0.4s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.628 total time=   0.4s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.653 total time=   0.4s\n",
      "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.605 total time=   0.5s\n",
      "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.586 total time=   0.5s\n",
      "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.618 total time=   0.5s\n",
      "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.629 total time=   0.5s\n",
      "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.652 total time=   0.5s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.601 total time=   0.4s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.587 total time=   0.4s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.598 total time=   0.4s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.600 total time=   0.4s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.612 total time=   0.4s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.588 total time=   0.5s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.601 total time=   0.5s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.595 total time=   0.5s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.598 total time=   0.5s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.612 total time=   0.5s\n",
      "[CV 1/5] END ........C=10, gamma=10, kernel=rbf;, score=0.728 total time=   0.3s\n",
      "[CV 2/5] END ........C=10, gamma=10, kernel=rbf;, score=0.705 total time=   0.3s\n",
      "[CV 3/5] END ........C=10, gamma=10, kernel=rbf;, score=0.702 total time=   0.3s\n",
      "[CV 4/5] END ........C=10, gamma=10, kernel=rbf;, score=0.744 total time=   0.3s\n",
      "[CV 5/5] END ........C=10, gamma=10, kernel=rbf;, score=0.733 total time=   0.3s\n",
      "[CV 1/5] END ....C=10, gamma=10, kernel=sigmoid;, score=0.496 total time=   0.4s\n",
      "[CV 2/5] END ....C=10, gamma=10, kernel=sigmoid;, score=0.526 total time=   0.4s\n",
      "[CV 3/5] END ....C=10, gamma=10, kernel=sigmoid;, score=0.488 total time=   0.4s\n",
      "[CV 4/5] END ....C=10, gamma=10, kernel=sigmoid;, score=0.502 total time=   0.4s\n",
      "[CV 5/5] END ....C=10, gamma=10, kernel=sigmoid;, score=0.505 total time=   0.4s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.679 total time=   0.3s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.673 total time=   0.3s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.669 total time=   0.4s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.706 total time=   0.4s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.703 total time=   0.4s\n",
      "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.570 total time=   0.4s\n",
      "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.535 total time=   0.5s\n",
      "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.504 total time=   0.5s\n",
      "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.560 total time=   0.4s\n",
      "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.515 total time=   0.5s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.620 total time=   0.4s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.600 total time=   0.4s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.656 total time=   0.4s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.679 total time=   0.4s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.705 total time=   0.4s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.589 total time=   0.4s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.609 total time=   0.4s\n",
      "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.626 total time=   0.3s\n",
      "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.565 total time=   0.3s\n",
      "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.612 total time=   0.4s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.607 total time=   0.4s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.591 total time=   0.4s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.626 total time=   0.4s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.629 total time=   0.4s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.658 total time=   0.4s\n",
      "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.599 total time=   0.5s\n",
      "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.580 total time=   0.5s\n",
      "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.614 total time=   0.5s\n",
      "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.623 total time=   0.5s\n",
      "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.647 total time=   0.5s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.605 total time=   0.4s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.586 total time=   0.4s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.618 total time=   0.4s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.629 total time=   0.4s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.652 total time=   0.4s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.605 total time=   0.5s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.586 total time=   0.5s\n",
      "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.618 total time=   0.5s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.629 total time=   0.5s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.652 total time=   0.5s\n",
      "[CV 1/5] END .......C=100, gamma=10, kernel=rbf;, score=0.728 total time=   0.5s\n",
      "[CV 2/5] END .......C=100, gamma=10, kernel=rbf;, score=0.716 total time=   0.5s\n",
      "[CV 3/5] END .......C=100, gamma=10, kernel=rbf;, score=0.702 total time=   0.5s\n",
      "[CV 4/5] END .......C=100, gamma=10, kernel=rbf;, score=0.736 total time=   0.5s\n",
      "[CV 5/5] END .......C=100, gamma=10, kernel=rbf;, score=0.747 total time=   0.6s\n",
      "[CV 1/5] END ...C=100, gamma=10, kernel=sigmoid;, score=0.496 total time=   0.4s\n",
      "[CV 2/5] END ...C=100, gamma=10, kernel=sigmoid;, score=0.526 total time=   0.4s\n",
      "[CV 3/5] END ...C=100, gamma=10, kernel=sigmoid;, score=0.488 total time=   0.4s\n",
      "[CV 4/5] END ...C=100, gamma=10, kernel=sigmoid;, score=0.502 total time=   0.4s\n",
      "[CV 5/5] END ...C=100, gamma=10, kernel=sigmoid;, score=0.505 total time=   0.4s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.727 total time=   0.4s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.709 total time=   0.4s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.713 total time=   0.4s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.730 total time=   0.4s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.735 total time=   0.6s\n",
      "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.570 total time=   0.6s\n",
      "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.536 total time=   0.7s\n",
      "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.513 total time=   0.7s\n",
      "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.560 total time=   0.6s\n",
      "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.515 total time=   0.6s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.661 total time=   0.4s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.623 total time=   0.4s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.661 total time=   0.4s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.678 total time=   0.4s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.689 total time=   0.4s\n",
      "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.590 total time=   0.3s\n",
      "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.611 total time=   0.3s\n",
      "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.626 total time=   0.3s\n",
      "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.560 total time=   0.3s\n",
      "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.631 total time=   0.3s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.609 total time=   0.4s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.591 total time=   0.4s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.619 total time=   0.4s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.645 total time=   0.4s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.661 total time=   0.4s\n",
      "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.582 total time=   0.5s\n",
      "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.584 total time=   0.5s\n",
      "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.580 total time=   0.5s\n",
      "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.582 total time=   0.5s\n",
      "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.575 total time=   0.5s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.605 total time=   0.4s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.586 total time=   0.4s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.618 total time=   0.4s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.629 total time=   0.4s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.652 total time=   0.4s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.605 total time=   0.6s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.586 total time=   0.6s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.618 total time=   0.7s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.629 total time=   0.7s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.652 total time=   0.6s\n",
      "[CV 1/5] END ......C=1000, gamma=10, kernel=rbf;, score=0.737 total time=   1.3s\n",
      "[CV 2/5] END ......C=1000, gamma=10, kernel=rbf;, score=0.691 total time=   1.8s\n",
      "[CV 3/5] END ......C=1000, gamma=10, kernel=rbf;, score=0.701 total time=   2.0s\n",
      "[CV 4/5] END ......C=1000, gamma=10, kernel=rbf;, score=0.733 total time=   1.9s\n",
      "[CV 5/5] END ......C=1000, gamma=10, kernel=rbf;, score=0.735 total time=   1.2s\n",
      "[CV 1/5] END ..C=1000, gamma=10, kernel=sigmoid;, score=0.496 total time=   0.4s\n",
      "[CV 2/5] END ..C=1000, gamma=10, kernel=sigmoid;, score=0.526 total time=   0.4s\n",
      "[CV 3/5] END ..C=1000, gamma=10, kernel=sigmoid;, score=0.488 total time=   0.4s\n",
      "[CV 4/5] END ..C=1000, gamma=10, kernel=sigmoid;, score=0.502 total time=   0.4s\n",
      "[CV 5/5] END ..C=1000, gamma=10, kernel=sigmoid;, score=0.505 total time=   0.4s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.727 total time=   0.8s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.703 total time=   1.0s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.709 total time=   1.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.742 total time=   1.2s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.735 total time=   0.9s\n",
      "[CV 1/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.570 total time=   0.4s\n",
      "[CV 2/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.536 total time=   0.5s\n",
      "[CV 3/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.513 total time=   0.5s\n",
      "[CV 4/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.560 total time=   0.5s\n",
      "[CV 5/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.515 total time=   0.7s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.689 total time=   0.8s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.669 total time=   1.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.676 total time=   0.9s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.703 total time=   1.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.694 total time=   0.9s\n",
      "[CV 1/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.589 total time=   0.4s\n",
      "[CV 2/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.612 total time=   0.4s\n",
      "[CV 3/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.626 total time=   0.5s\n",
      "[CV 4/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.560 total time=   0.4s\n",
      "[CV 5/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.632 total time=   0.5s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.626 total time=   0.5s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.598 total time=   0.5s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.657 total time=   0.6s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.654 total time=   0.8s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.675 total time=   0.8s\n",
      "[CV 1/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.585 total time=   0.6s\n",
      "[CV 2/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.571 total time=   0.6s\n",
      "[CV 3/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.580 total time=   0.6s\n",
      "[CV 4/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.581 total time=   0.5s\n",
      "[CV 5/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.537 total time=   0.5s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.609 total time=   0.4s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.591 total time=   0.5s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.626 total time=   0.4s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.629 total time=   0.4s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.661 total time=   0.5s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.605 total time=   0.7s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.586 total time=   0.7s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.618 total time=   0.7s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.628 total time=   0.6s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.652 total time=   0.6s\n",
      "The best possible parameters are:\n",
      "{'C': 100, 'gamma': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def hyperparameter_tuning(train_data):\n",
    "\n",
    "    global_feature_dict = Counter()\n",
    "    global_sentence_dict = defaultdict(set)\n",
    "    split_idx = int(len(train_data)/2)\n",
    "    \n",
    "    text_train = copy.deepcopy(train_data[:split_idx])\n",
    "    text_test = copy.deepcopy(train_data[split_idx:])\n",
    "    \n",
    "    num_train = copy.deepcopy(train_num_data[split_idx:])\n",
    "    # num_test = test_num_data[split_idx:]\n",
    "    \n",
    "    ## TF-IDF\n",
    "    build_global_dicts(text_train, global_feature_dict, global_sentence_dict)\n",
    "    assign_weights(text_train, global_sentence_dict)\n",
    "    assign_weights(text_test, global_sentence_dict)\n",
    "    LinearSVC_classifier = train_classifier(text_train)\n",
    "    test_featureset, test_labels = separate_test_set(text_test)\n",
    "    train_text_prediction = np.array(predict_labels(test_featureset, LinearSVC_classifier))\n",
    "    \n",
    "    ## Now we add 'text_prediction' as a feature to 'num_train'\n",
    "    ## Normalizing\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    train_text_prediction = le.fit_transform(train_text_prediction)\n",
    "    \n",
    "    num_train = copy.deepcopy(np.array(num_train))\n",
    "    x_train_num = num_train[:, :5]\n",
    "    y_train_num = num_train[:, -1]\n",
    "    \n",
    "    x_train_num = np.concatenate((x_train_num, train_text_prediction.reshape(x_train_num.shape[0],1)),  axis=1)\n",
    "    ## Now we normalize our new data consisting of 6 columns\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    x_train_num_standard = scaler.fit_transform(x_train_num)\n",
    "    \n",
    "    ## Now we do hyperparameter optimization\n",
    "    \n",
    "    # defining parameter range\n",
    "    param_grid = {'C': [1, 10, 100, 1000], \n",
    "              'gamma': [10, 1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf', 'sigmoid']} \n",
    "  \n",
    "    \n",
    "    grid = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "    # fitting the model for grid search\n",
    "    grid.fit(x_train_num_standard, y_train_num)\n",
    "    print('The best possible parameters are:')\n",
    "    print(grid.best_params_)\n",
    "\n",
    "hyperparameter_tuning(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab31e70-1ca1-475d-aadc-78c0dce8ecf3",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfb1e417-3e86-4024-9489-9caef8eee73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test fold form 0 to 818:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.53      0.64      0.58       338\n",
      "        REAL       0.70      0.60      0.64       481\n",
      "\n",
      "    accuracy                           0.61       819\n",
      "   macro avg       0.61      0.62      0.61       819\n",
      "weighted avg       0.63      0.61      0.62       819\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.70      0.66      0.68       338\n",
      "        REAL       0.77      0.80      0.78       481\n",
      "\n",
      "    accuracy                           0.74       819\n",
      "   macro avg       0.73      0.73      0.73       819\n",
      "weighted avg       0.74      0.74      0.74       819\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "test fold form 819 to 1637:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.54      0.64      0.59       376\n",
      "        REAL       0.64      0.54      0.59       443\n",
      "\n",
      "    accuracy                           0.59       819\n",
      "   macro avg       0.59      0.59      0.59       819\n",
      "weighted avg       0.60      0.59      0.59       819\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.71      0.62      0.66       376\n",
      "        REAL       0.71      0.79      0.75       443\n",
      "\n",
      "    accuracy                           0.71       819\n",
      "   macro avg       0.71      0.70      0.70       819\n",
      "weighted avg       0.71      0.71      0.71       819\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "test fold form 1638 to 2456:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.58      0.59      0.59       391\n",
      "        REAL       0.62      0.61      0.62       428\n",
      "\n",
      "    accuracy                           0.60       819\n",
      "   macro avg       0.60      0.60      0.60       819\n",
      "weighted avg       0.60      0.60      0.60       819\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.75      0.69      0.72       391\n",
      "        REAL       0.74      0.79      0.77       428\n",
      "\n",
      "    accuracy                           0.75       819\n",
      "   macro avg       0.75      0.74      0.74       819\n",
      "weighted avg       0.75      0.75      0.75       819\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "test fold form 2457 to 3275:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.57      0.64      0.60       357\n",
      "        REAL       0.69      0.64      0.66       462\n",
      "\n",
      "    accuracy                           0.64       819\n",
      "   macro avg       0.63      0.64      0.63       819\n",
      "weighted avg       0.64      0.64      0.64       819\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.74      0.66      0.69       357\n",
      "        REAL       0.75      0.82      0.79       462\n",
      "\n",
      "    accuracy                           0.75       819\n",
      "   macro avg       0.75      0.74      0.74       819\n",
      "weighted avg       0.75      0.75      0.75       819\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "test fold form 3276 to 4094:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.55      0.60      0.57       347\n",
      "        REAL       0.68      0.63      0.66       472\n",
      "\n",
      "    accuracy                           0.62       819\n",
      "   macro avg       0.62      0.62      0.62       819\n",
      "weighted avg       0.63      0.62      0.62       819\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.69      0.67      0.68       347\n",
      "        REAL       0.76      0.78      0.77       472\n",
      "\n",
      "    accuracy                           0.74       819\n",
      "   macro avg       0.73      0.73      0.73       819\n",
      "weighted avg       0.73      0.74      0.73       819\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "test fold form 4095 to 4913:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.51      0.57      0.54       350\n",
      "        REAL       0.65      0.59      0.61       469\n",
      "\n",
      "    accuracy                           0.58       819\n",
      "   macro avg       0.58      0.58      0.58       819\n",
      "weighted avg       0.59      0.58      0.58       819\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.69      0.62      0.65       350\n",
      "        REAL       0.73      0.79      0.76       469\n",
      "\n",
      "    accuracy                           0.72       819\n",
      "   macro avg       0.71      0.70      0.71       819\n",
      "weighted avg       0.71      0.72      0.71       819\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "test fold form 4914 to 5732:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.52      0.61      0.56       347\n",
      "        REAL       0.67      0.60      0.63       472\n",
      "\n",
      "    accuracy                           0.60       819\n",
      "   macro avg       0.60      0.60      0.60       819\n",
      "weighted avg       0.61      0.60      0.60       819\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.67      0.67      0.67       347\n",
      "        REAL       0.76      0.75      0.76       472\n",
      "\n",
      "    accuracy                           0.72       819\n",
      "   macro avg       0.71      0.71      0.71       819\n",
      "weighted avg       0.72      0.72      0.72       819\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "test fold form 5733 to 6551:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.56      0.65      0.60       356\n",
      "        REAL       0.69      0.61      0.65       463\n",
      "\n",
      "    accuracy                           0.63       819\n",
      "   macro avg       0.63      0.63      0.63       819\n",
      "weighted avg       0.64      0.63      0.63       819\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.70      0.64      0.67       356\n",
      "        REAL       0.74      0.79      0.77       463\n",
      "\n",
      "    accuracy                           0.73       819\n",
      "   macro avg       0.72      0.72      0.72       819\n",
      "weighted avg       0.73      0.73      0.72       819\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "test fold form 6552 to 7370:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.56      0.66      0.61       364\n",
      "        REAL       0.68      0.58      0.63       455\n",
      "\n",
      "    accuracy                           0.62       819\n",
      "   macro avg       0.62      0.62      0.62       819\n",
      "weighted avg       0.63      0.62      0.62       819\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.71      0.65      0.68       364\n",
      "        REAL       0.74      0.79      0.76       455\n",
      "\n",
      "    accuracy                           0.73       819\n",
      "   macro avg       0.73      0.72      0.72       819\n",
      "weighted avg       0.73      0.73      0.73       819\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "test fold form 7371 to 8192:\n",
      "Training Classifier...\n",
      "This is the classification report with using text features only:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.55      0.62      0.59       336\n",
      "        REAL       0.71      0.65      0.68       485\n",
      "\n",
      "    accuracy                           0.64       821\n",
      "   macro avg       0.63      0.64      0.63       821\n",
      "weighted avg       0.65      0.64      0.64       821\n",
      "\n",
      "This is the classification report using the combination of numerical and text features:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.69      0.62      0.66       336\n",
      "        REAL       0.76      0.81      0.78       485\n",
      "\n",
      "    accuracy                           0.73       821\n",
      "   macro avg       0.73      0.72      0.72       821\n",
      "weighted avg       0.73      0.73      0.73       821\n",
      "\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "This is the final result of prediction using text features only:\n",
      "Accuracy is: 0.6121762524929395\n",
      "Weighted Recall is: 0.6121762524929395\n",
      "Weighted Precision is: 0.62023980978101\n",
      "Weighted F1_score is: 0.6137382797722384\n",
      "-------------------------------------------------------\n",
      "This is the final result of prediction using combination of numerical and text features:\n",
      "Accuracy is: 0.7303459701754464\n",
      "Weighted Recall is: 0.7303459701754464\n",
      "Weighted Precision is: 0.7294112627828173\n",
      "Weighted F1_score is: 0.7287712408401882\n"
     ]
    }
   ],
   "source": [
    "[accuracy, recall, precision, _f1_score], [text_accuracy, text_recall, text_precision, text_f1_score] = cross_validate(train_data, train_num_data, 10)  #will work and output overall performance of p, r, f-score when cv implemented\n",
    "print('This is the final result of prediction using text features only:')\n",
    "print('Accuracy is: {}'.format(text_accuracy))\n",
    "print('Weighted Recall is: {}'.format(text_recall))\n",
    "print('Weighted Precision is: {}'.format(text_precision))\n",
    "print('Weighted F1_score is: {}'.format(text_f1_score))\n",
    "print('-------------------------------------------------------')\n",
    "print('This is the final result of prediction using combination of numerical and text features:')\n",
    "print('Accuracy is: {}'.format(accuracy))\n",
    "print('Weighted Recall is: {}'.format(recall))\n",
    "print('Weighted Precision is: {}'.format(precision))\n",
    "print('Weighted F1_score is: {}'.format(_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676f824-d877-4e82-a646-7f2bcd385ac1",
   "metadata": {},
   "source": [
    "# Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c469199e-ea03-4535-8f7c-f10dcde7dd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "This is the result using text features only:\n",
      "Accuracy is: 0.6051732552464617\n",
      "Weighted Recall is: 0.6051732552464617\n",
      "Weighted Precision is: 0.6073281993614473\n",
      "Weighted F1_score is: 0.6058770666224415\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.56      0.59      0.57       926\n",
      "        REAL       0.65      0.62      0.63      1123\n",
      "\n",
      "    accuracy                           0.61      2049\n",
      "   macro avg       0.60      0.60      0.60      2049\n",
      "weighted avg       0.61      0.61      0.61      2049\n",
      "\n",
      "------------------------------------------------------------\n",
      "This is the result using the combination of numerical and text features:\n",
      "Accuracy is: 0.7242557345046364\n",
      "Weighted Recall is: 0.7242557345046364\n",
      "Weighted Precision is: 0.7250399949024342\n",
      "Weighted F1_score is: 0.7209054051657503\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.73      0.62      0.67       926\n",
      "        REAL       0.72      0.81      0.76      1123\n",
      "\n",
      "    accuracy                           0.72      2049\n",
      "   macro avg       0.73      0.71      0.72      2049\n",
      "weighted avg       0.73      0.72      0.72      2049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train on 20% Test\n",
    "def final_training(train_data, train_num_data, test_data, test_num_data):\n",
    "    global_feature_dict = Counter()\n",
    "    global_sentence_dict = defaultdict(set)\n",
    "    ## This index is for halving the train dataset for my method in training which is fully explained in report and alswo inside the cross validation function\n",
    "    split_idx = int(len(train_data)/2)\n",
    "    \n",
    "    ## These two dataset are for training and testing the textual classifier (train of half of train data, test on the other half)\n",
    "    text_train = copy.deepcopy(train_data[:split_idx])\n",
    "    text_test = copy.deepcopy(train_data[split_idx:])\n",
    "    \n",
    "    ## training dataset with numerical features (second half of dataset, because we train our textual classifiers on the first half and we know the true label)\n",
    "    num_train = copy.deepcopy(train_num_data[split_idx:])\n",
    "    \n",
    "    ## TF-IDF\n",
    "    build_global_dicts(text_train, global_feature_dict, global_sentence_dict)\n",
    "    assign_weights(text_train, global_sentence_dict)\n",
    "    assign_weights(text_test, global_sentence_dict)\n",
    "    LinearSVC_classifier = train_classifier(text_train)\n",
    "    test_featureset, test_labels = separate_test_set(text_test)\n",
    "    train_text_prediction = np.array(predict_labels(test_featureset, LinearSVC_classifier))\n",
    "    \n",
    "    ## Now we add 'text_prediction' as a feature to 'num_train'\n",
    "    ## Normalizing\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    train_text_prediction = le.fit_transform(train_text_prediction)\n",
    "    \n",
    "    num_train = copy.deepcopy(np.array(num_train))\n",
    "    x_train_num = num_train[:, :5]\n",
    "    y_train_num = num_train[:, -1]\n",
    "    \n",
    "    x_train_num = np.concatenate((x_train_num, train_text_prediction.reshape(x_train_num.shape[0],1)),  axis=1)\n",
    "    ## Now we normalize our new data consisting of 6 columns (5 numerical features + 1 features which is prediction by textual classifier)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    x_train_num_standard = scaler.fit_transform(x_train_num)\n",
    "    ## Now we train data on our final numeric classifier\n",
    "    clf = svm.SVC(C=100, gamma=1)\n",
    "    clf.fit(x_train_num_standard, y_train_num)\n",
    "    \n",
    "    ## So far we train our combination of classifiers, now we test our text_classifier on test data, to add it as a new column to the numeric dataset for training numerical classifier\n",
    "    test_featureset, test_labels = separate_test_set(test_data)\n",
    "    test_text_prediction = predict_labels(test_featureset, LinearSVC_classifier)\n",
    "    \n",
    "    ## Prediction with only text features\n",
    "    print('This is the result using text features only:')\n",
    "    print('Accuracy is: {}'.format(accuracy_score(test_labels, test_text_prediction)))\n",
    "    print('Weighted Recall is: {}'.format(recall_score(test_labels, test_text_prediction, average='weighted')))\n",
    "    print('Weighted Precision is: {}'.format(precision_score(test_labels, test_text_prediction, average='weighted')))\n",
    "    print('Weighted F1_score is: {}'.format(f1_score(test_labels, test_text_prediction, average='weighted')))\n",
    "    print('\\n')\n",
    "    print(classification_report(test_labels, test_text_prediction))\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    ## Now we consider the text classifier prediction as a new feature for our numeric dataset\n",
    "    ## Convert the predicition of text classifier (Real, Fake) to (1, 0) \n",
    "    _le = preprocessing.LabelEncoder()\n",
    "    test_text_prediction = _le.fit_transform(test_text_prediction)\n",
    "    \n",
    "    ## Now we build our test dataset\n",
    "    test_num_data = copy.deepcopy(np.array(test_num_data))\n",
    "    x_test_num = test_num_data[:, :5]\n",
    "    y_test_num = test_num_data[:, -1]\n",
    "    ## Add text feature to num_data\n",
    "    x_test_num = np.concatenate((x_test_num, test_text_prediction.reshape(x_test_num.shape[0],1)),  axis=1)\n",
    "    ## Now we normalize our test_dataset with the standardizer that we already have\n",
    "    x_test_num_standard = scaler.transform(x_test_num)\n",
    "\n",
    "    ## Now we have test data, it's time for testing our final classifier --> clf\n",
    "    final_prediction = clf.predict(x_test_num_standard)\n",
    "    \n",
    "    print('This is the result using the combination of numerical and text features:')\n",
    "    print('Accuracy is: {}'.format(accuracy_score(test_labels, final_prediction)))\n",
    "    print('Weighted Recall is: {}'.format(recall_score(test_labels, final_prediction, average='weighted')))\n",
    "    print('Weighted Precision is: {}'.format(precision_score(test_labels, final_prediction, average='weighted')))\n",
    "    print('Weighted F1_score is: {}'.format(f1_score(test_labels, final_prediction, average='weighted')))\n",
    "    print('\\n')\n",
    "    print(classification_report(test_labels, final_prediction))\n",
    "    \n",
    "final_training(train_data, train_num_data, test_data, test_num_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
